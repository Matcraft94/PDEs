{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from matplotlib.ticker import LinearLocator, FormatStrFormatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the neural network class\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, inputs, num_layers, num_neurons):\n",
    "        super(Net, self).__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.layers.append(nn.Linear(inputs, num_neurons))\n",
    "        for i in range(num_layers - 1):\n",
    "            self.layers.append(nn.Linear(num_neurons, num_neurons))\n",
    "        self.output_layer = nn.Linear(num_neurons, 1)\n",
    "\n",
    "    def forward(self, x, y, t):\n",
    "        inputs = torch.cat([x, y, t], axis=1)\n",
    "        out = inputs\n",
    "        for layer in self.layers:\n",
    "            out = torch.sin(layer(out))\n",
    "        output = self.output_layer(out)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### (2) Model\n",
    "num_layers = 10\n",
    "num_neurons = 10\n",
    "\n",
    "net = Net(3, num_layers, num_neurons)\n",
    "net = net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loss function and optimizer\n",
    "mse_cost_function = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(net.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir la función que representa la EDP\n",
    "def f(x, y, t, c, net):\n",
    "    # u = net(torch.cat([x, y], axis=1), t)\n",
    "    u = net(x, y, t)\n",
    "    u_x = torch.autograd.grad(u.sum(), x, create_graph=True)[0]\n",
    "    u_y = torch.autograd.grad(u.sum(), y, create_graph=True)[0]\n",
    "    u_t = torch.autograd.grad(u.sum(), t, create_graph=True)[0]\n",
    "    u_xx = torch.autograd.grad(u_x.sum(), x, create_graph=True)[0]\n",
    "    u_yy = torch.autograd.grad(u_y.sum(), y, create_graph=True)[0]\n",
    "    u_tt = torch.autograd.grad(u_t.sum(), t, create_graph=True)[0]\n",
    "    f_val = u_tt - c**2 * (u_xx + u_yy)\n",
    "    return f_val.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the initial condition\n",
    "def gaussian(x, y):\n",
    "    return np.exp(-((x-0.5)**2 + (y-0.5)**2)/0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir la función que representa las condiciones de borde\n",
    "def boundary_condition(x, y, t, c):\n",
    "    return torch.tensor([0.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir la función para generar datos de entrenamiento\n",
    "def generate_training_data(n_t, n_x, n_y):\n",
    "    t = np.random.uniform(low=0.0, high=1.0, size=(n_t, 1))\n",
    "    x = np.random.uniform(low=0.0, high=2.0, size=(n_x, 1))\n",
    "    y = np.random.uniform(low=0.0, high=2.0, size=(n_y, 1))\n",
    "    return t, x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir los parámetros de entrenamiento\n",
    "num_layers = 10\n",
    "num_neurons = 10\n",
    "learning_rate = 0.001\n",
    "iterations = 20000\n",
    "n_t = 500\n",
    "n_x = 100\n",
    "n_y = 100\n",
    "\n",
    "c = 1.0\n",
    "\n",
    "a = 0.0\n",
    "b = 1.0\n",
    "t_a = 0.0\n",
    "t_b = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Set up the boundary conditions\n",
    "# c = 1.\n",
    "# n_t = 100\n",
    "# n_x = 100\n",
    "# n_y = 100\n",
    "# x_min, x_max = -5, 5\n",
    "# y_min, y_max = -5, 5\n",
    "# t_min, t_max = 0, 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir la red neuronal\n",
    "net = Net(inputs=3, num_layers=num_layers, num_neurons=num_neurons).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir la función de costo y el optimizador\n",
    "mse_cost_function = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar los datos de entrenamiento\n",
    "t_train, x_train, y_train = generate_training_data(n_t, n_x, n_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_bc = np.random.uniform(low=a, high=b, size=(n_t,1))\n",
    "y_bc = np.random.uniform(low=a, high=b, size=(n_t,1))\n",
    "t_bc = np.zeros((n_t,1))\n",
    "# compute u based on BC\n",
    "u_bc = 6*np.exp(-3*x_bc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Det-Pc\\anaconda3\\envs\\pytorch-C-DL\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([500, 1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Training Loss: tensor(4.3678, device='cuda:0')\n",
      "1000 Training Loss: tensor(1.7776, device='cuda:0')\n",
      "2000 Training Loss: tensor(2.0359, device='cuda:0')\n",
      "3000 Training Loss: tensor(0.8104, device='cuda:0')\n",
      "4000 Training Loss: tensor(0.7641, device='cuda:0')\n",
      "5000 Training Loss: tensor(0.6026, device='cuda:0')\n",
      "6000 Training Loss: tensor(0.5678, device='cuda:0')\n",
      "7000 Training Loss: tensor(0.9221, device='cuda:0')\n",
      "8000 Training Loss: tensor(0.8776, device='cuda:0')\n",
      "9000 Training Loss: tensor(0.5199, device='cuda:0')\n",
      "10000 Training Loss: tensor(0.5101, device='cuda:0')\n",
      "11000 Training Loss: tensor(0.7546, device='cuda:0')\n",
      "12000 Training Loss: tensor(0.4329, device='cuda:0')\n",
      "13000 Training Loss: tensor(1.2174, device='cuda:0')\n",
      "14000 Training Loss: tensor(0.3318, device='cuda:0')\n",
      "15000 Training Loss: tensor(0.3077, device='cuda:0')\n",
      "16000 Training Loss: tensor(0.3147, device='cuda:0')\n",
      "17000 Training Loss: tensor(0.2969, device='cuda:0')\n",
      "18000 Training Loss: tensor(0.3704, device='cuda:0')\n",
      "19000 Training Loss: tensor(0.6444, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(iterations):\n",
    "    optimizer.zero_grad() # to make the gradients zero\n",
    "    \n",
    "    # Loss based on boundary conditions\n",
    "    pt_x_bc = Variable(torch.from_numpy(x_bc).float(), requires_grad=False).to(device)\n",
    "    pt_y_bc = Variable(torch.from_numpy(y_bc).float(), requires_grad=False).to(device)\n",
    "    pt_t_bc = Variable(torch.from_numpy(t_bc).float(), requires_grad=False).to(device)\n",
    "    pt_u_bc = Variable(torch.from_numpy(u_bc).float(), requires_grad=False).to(device)\n",
    "    \n",
    "    net_bc_out = net(pt_x_bc, pt_y_bc, pt_t_bc) # output of u(x,t)\n",
    "    mse_u = mse_cost_function(net_bc_out, pt_u_bc)\n",
    "    \n",
    "    # Loss based on PDE\n",
    "    x_collocation = np.random.uniform(low=a, high=b, size=(500,2))\n",
    "    y_collocation = np.random.uniform(low=a, high=b, size=(500,2))\n",
    "    t_collocation = np.random.uniform(low=t_a, high=t_b, size=(500,1))\n",
    "    all_zeros = np.zeros((500,1))\n",
    "    \n",
    "    pt_x_collocation = Variable(torch.from_numpy(x_collocation).float(), requires_grad=True).to(device)\n",
    "    pt_y_collocation = Variable(torch.from_numpy(y_collocation).float(), requires_grad=True).to(device)\n",
    "    pt_t_collocation = Variable(torch.from_numpy(t_collocation).float(), requires_grad=True).to(device)\n",
    "    pt_all_zeros = Variable(torch.from_numpy(all_zeros).float(), requires_grad=False).to(device)\n",
    "    \n",
    "    f_out = f(pt_x_collocation[:,0:1], pt_y_collocation[:,0:1], pt_t_collocation, c, net) # output of f(x,t)\n",
    "    mse_f = mse_cost_function(f_out, pt_all_zeros)\n",
    "    \n",
    "    # Combining the loss functions\n",
    "    loss = mse_u + mse_f\n",
    "    \n",
    "    loss.backward() # This is for computing gradients using backward propagation\n",
    "    optimizer.step() # This is equivalent to : theta_new = theta_old - alpha * derivative of J w.r.t theta\n",
    "\n",
    "    with torch.autograd.no_grad():  \n",
    "        if epoch % 1000 == 0:\n",
    "            print(epoch, \"Training Loss:\", loss.data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-C-DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "85b52fbe45fd3d3f6426508f2b1ceb63e7294645d1a7097c9a6e2bd314b42ccf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
